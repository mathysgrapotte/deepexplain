{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Tn0BUw1cyhA"
   },
   "source": [
    "## MNIST: binary CNN implementation & training\n",
    "\n",
    "In this tutorial, we will work with a simple CNN trained on two classes of MNIST.\n",
    "\n",
    "Below, we implement the standard pipeline and save the model for later inference and explaining.\n",
    "With the code and comments, the notebook is pretty much self-explaining, so we add additional text only when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Z4yFCZyucyhB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from data_and_models import mnist_binary_cnn,create_mnist_set # implemented in a separate script for later use\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vc4djkgZcyhB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes=[1,8] # we'll work with these only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rIbP1c_gcyhB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainset=create_mnist_set(root='./data',train=True,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HIvcxNSjcyhC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testset=create_mnist_set(root='./data',train=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qd67wBqqcyhC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(trainset,batch_size=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "n2yJJEIgcyhC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader=DataLoader(testset,batch_size=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uv7cechmcyhC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def binarize_labels(labels,classes): # classes[0] becomes ~0, classes[1] ~1\n",
    "    \n",
    "    # the reason why we use it: NN outputs a single probability: need to binarize class labels\n",
    "\n",
    "    return ((labels-classes[0])/(classes[1]-classes[0])).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jW66vhikcyhC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def trainstep(model,optimizer,batch):\n",
    "\n",
    "    labels=binarize_labels(batch[1],classes)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    probs=model(batch[0])[:,0]\n",
    "\n",
    "    loss=model.loss(probs,labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.detach()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "24KCSs9ocyhD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(model,batch):\n",
    "\n",
    "    n=batch[0].shape[0]\n",
    "    \n",
    "    labels=binarize_labels(batch[1],classes)\n",
    "    probabilities=model(batch[0])[:,0]\n",
    "    \n",
    "    correct=0\n",
    "\n",
    "    for i in range(n):\n",
    "        if probabilities[i]>0.5 and labels[i]>0.5:\n",
    "            correct+=1\n",
    "        elif probabilities[i]<=0.5 and labels[i]<0.5:\n",
    "            correct+=1\n",
    "    return correct/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gSJCEmPgcyhD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model=mnist_binary_cnn() # standard choice to rescale image and crossentropy - see the defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lQRrG7_0cyhD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the training comes, finally. Note that our objective was to train a simple model, so we didn't bother with setting up validation cycles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0vBmtBWccyhD",
    "outputId": "eb3901f8-84b4-4cf6-e277-2bddff8e5c2d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 completed\n",
      "loss: 0.659585\n",
      "accuracy: 0.720292\n",
      "epoch 2 completed\n",
      "loss: 0.362096\n",
      "accuracy: 0.929168\n",
      "epoch 3 completed\n",
      "loss: 0.150800\n",
      "accuracy: 0.956006\n",
      "epoch 4 completed\n",
      "loss: 0.106130\n",
      "accuracy: 0.965397\n",
      "epoch 5 completed\n",
      "loss: 0.087141\n",
      "accuracy: 0.970371\n",
      "epoch 6 completed\n",
      "loss: 0.075571\n",
      "accuracy: 0.974908\n",
      "epoch 7 completed\n",
      "loss: 0.067968\n",
      "accuracy: 0.977619\n",
      "epoch 8 completed\n",
      "loss: 0.062334\n",
      "accuracy: 0.979273\n",
      "epoch 9 completed\n",
      "loss: 0.057479\n",
      "accuracy: 0.980146\n",
      "epoch 10 completed\n",
      "loss: 0.053844\n",
      "accuracy: 0.981429\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): # for such a simple problem, 10 epoch shall do\n",
    "    full_loss=0\n",
    "    full_accuracy=0\n",
    "    for j,batch in enumerate(train_dataloader):\n",
    "        loss=trainstep(model,optimizer,batch)\n",
    "        full_loss=full_loss*j/(j+1)+loss.detach()/(j+1) # compute average in a 'sliding' manner, maybe familiar from RL\n",
    "        full_accuracy=full_accuracy*j/(j+1)+accuracy(model,batch)/(j+1)\n",
    "    print('epoch %d completed'%(i+1))\n",
    "    print('loss: %f' % (full_loss))\n",
    "    print('accuracy: %f'%(full_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get some feeling of how much of an overfit regime we are in, calculate accuracy on a valid batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FwmITV9ncyhf"
   },
   "outputs": [],
   "source": [
    "val_batch=next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model,val_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we store the model and the classes so that in later parts, we only need to reload them without re-training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/mnist_binary_classes.txt','wb') as f:\n",
    "    pickle.dump(classes,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'models/mnist_binary_model.pth')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project_try.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
